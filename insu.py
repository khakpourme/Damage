import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

import matplotlib.pyplot as plt

from subprocess import check_output
from datetime import time
# print(check_output(["ls", "../input"]).decode("utf8"))

def time_to_seconds(time):
    return time.hour * 3600 + time.minute * 60 + time.second

df = pd.read_csv("Pdata_2012.csv")
df = df.drop("ID", axis=1)
df = df.drop("Navn", axis=1)

# one hot encode categorical columns
# columns = ["day_of_week", "month", "hour"]
# df = pd.get_dummies(df, columns=columns)
# df.head(10)

# Extract the training and test data
data = df.values
X = data[:, 1:52]  # all rows, no label
y = data[:, 69]  # all rows, label only
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

# Scale the data to be between -1 and 1
# scaler = StandardScaler()
# scaler.fit(X_train)
# X_train = scaler.transform(X_train)
# X_test = scaler.transform(X_test)

# Establish model
model = RandomForestRegressor(n_jobs=-1)

# Try different numbers of n_estimators - this will take a minute or so
estimators = np.arange(10, 200, 10)
scores = []
for n in estimators:
    model.set_params(n_estimators=n)
    model.fit(X_train, y_train)
    scores.append(model.score(X_test, y_test))
plt.title("Effect of n_estimators")
plt.xlabel("n_estimator")
plt.ylabel("score")
plt.plot(estimators, scores)